## Chapter 3: Conceptualizing Interaction

- **3.1 Introduction**

- **3.2 Conceptualizing Interaction**
  - Working Through Assumptions and Claims (Box 3.1)

- **3.3 Conceptual Models**
  - Design Concept (Box 3.2)
  - A Classic Conceptual Model: The Xerox Star (Box 3.3)

- **3.4 Interface Metaphors**
  - Why Are Metaphors So Popular? (Box 3.4)

- **3.5 Interaction Types**
  - 3.5.1 Instructing
    - Interaction with Vending Machines (Activity 3.3)
  - 3.5.2 Conversing
  - 3.5.3 Manipulating
    - Direct Manipulation Framework
  - 3.5.4 Exploring
  - 3.5.5 Responding

- **3.6 Paradigms, Visions, Challenges, Theories, Models, and Frameworks**
  - 3.6.1 Paradigms
  - 3.6.2 Visions
  - 3.6.3 Challenges
  - 3.6.4 Theories
  - 3.6.5 Models
  - 3.6.6 Frameworks
    - Closing the Gap Between Conceptual and Design Models (Box 3.5)

- **Dilemma**: Who Is in Control?
- **In-Depth Activity**: Comparing Paperback Books vs E-books and Paper Maps vs Map Apps

- **Summary and Key Points**


---
### 3.1 Introduction 📸

- **Importance of Conceptualizing Ideas**:
  - Conceptualization helps define what a proposed product will do.
  - This can serve as a proof of concept, related to the double diamond framework phases—“discover” and “define.”

- **Reality Check for Ideas**:
  - Initial conceptualization scrutinizes ideas for feasibility.
  - It forces designers to clarify how users will understand, learn about, and interact with the product.

- **Voice-Assisted Mobile Robot Example**:
  - Designers should identify the problem being solved.
  - Example scenario: A voice-assisted mobile robot for restaurant use.
  - Initial claims focused on the robot's benefits but not on a real problem.
  - An actual problem might be difficulty in recruiting good waiters.

- **Questions to Address for Design**:
  - How intelligent must the robot be?
  - How will the robot move and interact with customers?
  - How will customers perceive the robot—fun or gimmicky?

- **Comparative Robot Design Example**:
  - Another robot server designed after the pandemic helps waiters, focusing on delivering food.
  - This robot is not human-like and acts as a tool to assist rather than replace waiters.

- **Early Ideation Considerations**:
  - Consider unknowns and show the sources of inspiration.
  - Identify relevant theories or research to support initial ideas.

- **Articulating Ideas as Concepts**:
  - Asking questions, articulating assumptions, and expressing ideas as concepts help clarify the product's design.
  - This early ideation helps in moving from vague ideas to concrete models with defined features and functionality. 

### 3.2 Conceptualizing Interaction 🎨💡

- **Identify Assumptions and Claims** 🤔
  - **Assumption**: Taking something for granted, needing investigation (e.g., people want self-driving cars).
  - **Claim**: A statement assumed true but open to question (e.g., people will feel safe in self-driving cars).
  - Assumptions focus on current situations, while claims are about potential future outcomes. 📅🔮

- **Clarify Your Design Ideas** ✍️
  - Write down and evaluate assumptions/claims.
  - Identify vague ideas to refine and strengthen them.
  - Helps improve design ideas or create new user experiences that don't yet exist. 🚀

- **Team Scenario: Improving a Browser** 📱🌐
  - The team assumes there's a usability problem since customers switched to a rival browser.
  - Claims improvement will win customers back by making the interface simpler and more attractive. 🎨✨
  - User research reveals usability problems, like difficulties with the bookmark function. 📑❌
  - Diverse perspectives help identify conflicting views and challenge vague assumptions. 🗣️🤷‍♂️

- **Example Questions to Explore Problems** ❓
  - Are there problems with the product/user experience? 🔍
  - What evidence supports these problems? 📊
  - How can the design solve these problems? 🔧

- **Lessons from 3D TV and Curved TV Failures** 📺❌
  - Assumed people would want an enhanced viewing experience akin to the cinema.
  - Reality: 3D glasses were cumbersome, and benefits of curved TVs weren’t worth the cost.
  - Highlight: Importance of understanding actual user needs vs. assumed desires. 📉👥

- **Importance of Defining Assumptions Early** ⏳
  - Clarify assumptions about problems/opportunities early and throughout the project.
  - Leads to better articulation of conceptual models that support the intended user experience. 🎯👥✨

  
### 3.3 Conceptual Models 🧠🔍

- **Definition of Conceptual Models** 📜
  - A **conceptual model** is a simplified description of how a system operates, providing a high-level structure of a design or interface. It helps clarify the **problem space** and articulate the design. 
  - **Jeff Johnson and Austin Henderson (2002)** defined a conceptual model as "a high-level description of how a system is organized and operates." This helps designers refine their ideas before implementing the design. 🛠️✨

- **Core Components of Conceptual Models** 🗂️
  - **Metaphors and Analogies**: Convey how to use a product (e.g., browsing and bookmarking). 📚🔖
  - **Concepts and Operations**: Describe task-domain objects and what can be done with them (e.g., saving, revisiting). 💾↩️
  - **Relationships Between Concepts**: Specify how different components relate to each other (e.g., a folder containing files). 📁🗃️
  - **Mapping Concepts to User Experience**: Defines how concepts influence user actions (e.g., revisiting a webpage using bookmarks or history lists). 🌐📑

- **Debating User Experience** 💬⚖️
  - Discussing different **metaphors** helps the design team decide the best ways to support user actions, such as browsing or categorizing content.
  - This process can involve deciding between metaphors like folders or bars for organizing information. 📂📊

- **Simple vs. Complex Models** 🌀❌
  - The **best conceptual models** are intuitive, appearing simple to users.
  - However, **upgraded applications** can become too complex when new features are repeatedly added, frustrating users who preferred older methods (e.g., changes to Facebook’s newsfeed). 🤯💬

- **Representing Conceptual Models** 🖊️🖼️
  - Can be represented as **textual descriptions or diagrams** depending on the preferred language of the team. It serves as a **blueprint** for developing more detailed designs. ✍️📝

- **Examples of Conceptual Models** 📖🖥️
  - Classic models like the **shopping cart** metaphor for online shopping help customers intuitively add items and proceed to checkout. 🛒✅
  - **Xerox Star Interface (1981)**: Developed by Xerox, introduced icons like paper, folders, and mailboxes, making complex actions understandable by relating them to physical objects. It became a foundation for today’s desktop interfaces. 📄📂🖥️

- **Classic Innovations That Changed Interaction** ✨🔄
  - **Desktop Metaphor** (Xerox, late 1970s): Made office tasks accessible and visual. 🖥️
  - **Digital Spreadsheet** (Dan Bricklin & Bob Frankston, late 1970s): Enabled flexible calculations through interactive boxes. 📊📈
  - **World Wide Web** (Tim Berners-Lee, late 1980s): Made information access universal, expanding activities like browsing, learning, and communication. 🌍💻

### **Quotes & Attributions**:
- **Jeff Johnson & Austin Henderson (2002)**: Defined the conceptual model as a "high-level description of how a system is organized and operates." 📜✨
- **Hazlewood et al. (2010)**: Illustrated an ambient display design aimed at changing people’s behavior—like taking the stairs instead of the elevator. 🏢✨
- **Smith et al. (1982); Miller & Johnson (1996)**: Described the development of the **Xerox Star interface**, a foundational conceptual model for personal computing. 📂📊


### 3.4 Interface Metaphors 🖥️🔍

- **Role of Interface Metaphors** 🎭
  - **Metaphors** play a central role in conceptual models, providing users with familiar elements to understand complex systems. E.g., **the desktop metaphor** makes navigating a computer like managing a physical desk. 🗃️💻

- **Search Engine Metaphor** 🔍⚙️
  - The term **"search engine"** was coined in the 1990s, comparing software that indexes and retrieves files to a mechanical engine. It gives users a sense of "finding things" but with algorithms and listings, unlike physical engines. 🛠️📂

- **Shopping Cart Metaphor** 🛒
  - Many e-commerce sites use the **shopping cart/basket** metaphor, which reassures users, allowing them to **"add to cart"** without immediate commitment. This familiar interaction improves the online shopping experience. 🛍️💳

- **Metaphors in UX Design** 💡
  - The **card metaphor** has become popular in social media (e.g., Twitter, Pinterest). It represents content in an intuitive, organized way, similar to physical cards like playing cards or business cards. Users can easily flick, sort, or theme these digital cards, making them great for UX. 📇💌

- **Everyday Usage of Metaphors** 💬
  - Many metaphors become **part of everyday language**, like "screen time" or "Googling." They help make technology-related concepts more relatable and easier to understand. 💻🗣️

- **Challenges with Metaphors** ⚠️
  - Metaphors can also clash with expectations. For example, the **recycle bin icon** on the desktop logically should be "under the desk," but due to visibility issues, it is kept on the desktop, which irked some users. 🗑️💢

- **Why Are Metaphors Popular?** 🤔
  - **Lakoff and Johnson (1980)** explained that metaphors help in understanding **abstract or unfamiliar** concepts by relating them to **familiar, concrete** terms. 📝🔗
  - **Metaphors in Education**: Teachers often use metaphors to introduce new material by relating it to something students already understand. For instance, **BBC** used the analogy of roads and towns to explain the difference between the **web and the Internet**. 🌐🚗

- **Using Metaphors in Different Ways** 🚦
  - Metaphors are used for:
    - **Conceptualizing activities** (e.g., live streaming). 📡
    - **Creating interface elements** (e.g., the card metaphor for content). 🃏
    - **Visualizing operations** (e.g., shopping cart icon to purchase items online). 🛒

- **Criticism of Interface Metaphors** 📝❌
  - **Alan Cooper (2020)** suggested abandoning metaphors at interfaces. Instead, he argues that interfaces should be explained based on **concepts, functions, and relationships** to avoid confusion with complex systems. ⚙️📉

### **Quotes & Attributions**:
- **Lakoff & Johnson (1980)**: Explained the importance of metaphors for understanding unfamiliar concepts through familiar comparisons. 🔍✨
- **Alan Cooper (2020)**: Criticized the use of metaphors at interfaces, emphasizing the need to focus on concepts and system relationships instead. ❌🎭
- **BBC BiteSize**: Explained the difference between the web and the Internet using an analogy of roads and towns. 🚗🌐

Here's a summary of Section 3.5 with an emojified format and proper citations:

### 3.5 Interaction Types 🖥️🤝

**Interaction types** are the ways a user interacts with a product, forming the basis of the user experience. There are five main types of interactions:

1. **Instructing** 📝📢
   - The user **issues commands** to the system, such as typing commands, selecting from menus, pressing buttons, or using voice commands. This type is efficient for tasks that need frequent repetition, like deleting, saving, or moving files. 📂🔄

2. **Conversing** 🗣️💬
   - The user **talks or interacts in dialogue** with the system. It could be typing a question, using voice commands, or interacting with chatbots (like Siri or Alexa). The system acts as a partner, often in a conversational user interface (CUI). Think of having a friendly conversation with a chatbot to solve your problem. 🤖🗨️

3. **Manipulating** 🖱️📦
   - Users **interact with digital objects** in virtual or physical space. Examples include dragging, zooming, and placing items. It uses familiar, real-world interactions—like moving documents on a computer similar to shifting physical papers on a desk. The goal is to make the digital environment intuitive. 📂➡️💻

4. **Exploring** 🏞️🕶️
   - Users **move through virtual or physical environments**—like navigating a 3D space, exploring augmented reality (AR), or interacting in sensor-enabled smart rooms. This approach lets users explore intuitively using their real-world experiences. 🌌🏃‍♂️

5. **Responding** 📲🔔
   - The **system initiates interaction**, and the user responds. For example, when Netflix pauses and asks, "Are you still watching?" or location-based alerts pop up on mobile devices. This makes the system more proactive in guiding the user. ⏯️📍

**Notes on Design Use** 🛠️💡
- These interaction types are **not mutually exclusive**—users can switch between different types based on the task.
- Designers need to select interaction types based on **what provides the best experience**—considering the trade-offs, pros, and cons. ⚖️✨

**Quotes & Attributions**:
- **Preece et al. (2002)**: Identified the first four interaction types—**instructing, conversing, manipulating, and exploring**. 🔍📜
- **Christopher Lueg et al. (2019)**: Introduced the fifth type—**responding**—focusing on systems that initiate actions to which users respond. 🛎️✅


#### 3.5.1 Instructing 📝📣

**Instructing Interaction** is about **telling a system what to do**. This could be giving a command or selecting an option—simple, quick, and efficient! Let's break it down: 

1. **How It Works** ⚙️
   - **Users tell the system what to do**—e.g., tell the time, print a document, or remind them of an appointment. 🕒🖨️
   - Commands can be issued through **voice, button press, or menus**. Examples are found in home entertainment systems, consumer electronics, and software. 🎮🎶🖱️

2. **Why It’s Beneficial** 💡
   - **Quick & efficient**: Ideal for repetitive tasks like saving, deleting, and organizing files. It allows users to complete operations with minimal effort. ⚡📁
  
3. **Vending Machine Example** 🥤🍫
   - **Different Types of Interactions**:
     - **Simple button press**: Select a drink by pressing a large button.
     - **Complex codes and keys**: Some machines require inputting a code, which can cause user errors. 🔢❌
     - **Digital touch screens**: Display choices clearly, minimizing errors, and use visual metaphors (e.g., candy store) to entice users. 🍬💳

**Quotes & Attributions**:
- **Preece et al. (2002)**: Highlighted instructing as a primary interaction type for **fast and effective user-system commands**. 📝✨

#### 3.5.2 Conversing 💬🤖

**Conversing Interaction** is about having a **two-way communication with a system** that feels like talking to another person. The system acts as a dialogue partner, making it interactive and human-like! Here’s a breakdown:

1. **Conversational Interaction Explained** 🗣️
   - Users engage in a **two-way conversation** with the system, unlike giving one-way commands. The system acts like a conversational partner, rather than simply following instructions. 👫🤖
   - Common examples include **chatbots, advisory systems, voice assistants (e.g., Siri)**, and customer support systems. 📞💻

2. **Simple vs. Complex Conversations** 🧠💡
   - **Simple Conversations**: Voice-recognition systems for banking or ticket booking. Users provide keywords or numbers like "yes" or "no." 💳🎟️
   - **Complex Conversations**: Natural language processing for more detailed queries, like "How do I change the margin widths?" 📝

3. **Benefits** 🌟
   - Allows for **natural and familiar interactions**: People interact in ways similar to how they would with another person. Examples include asking Siri to schedule a meeting or check the weather. 🗓️☂️

4. **Challenges** 🚧
   - **Cumbersome interactions**: Sometimes, menu-driven conversations become repetitive and annoying, especially with automated phone systems where users have to navigate through many levels of options before getting what they need. 📞😫

**Quotes & Attributions**:
- **Preece et al. (2002)**: Defined conversing as an interaction type where systems act as conversational partners, supporting natural and dialogue-based user experiences. 💬✨

